{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load cleaned up version of dataset from 2012 to 2018.  Drop geographic information about employer and worksite to reduce dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('/Users/ml/Desktop/Udacity_ML_Capstone/data/H1B_15-18_new.pickle')\n",
    "df.drop(columns=['EMPLOYER_CITY','JOB_TITLE','EMPLOYER_NAME'], inplace=True)\n",
    "df.drop(columns=['EMPLOYER_STATE','WORKSITE_STATE'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_df = df[df['CASE_STATUS']=='DENIED']\n",
    "zeros_df = df[df['CASE_STATUS']=='CERTIFIED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([ones_df, zeros_df.sample(frac=0.02, random_state=99)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37310, 11)\n"
     ]
    }
   ],
   "source": [
    "ones_df.head()\n",
    "print(ones_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1656369, 11)\n"
     ]
    }
   ],
   "source": [
    "zeros_df.head()\n",
    "print(zeros_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use column 'CASE_STATUS' as our label.  DENIED will be 1 and CERTIFIED will be 0 after it gets incoded by label_encoder.\n",
    "\n",
    "Normalize PREVAILING_WAGE using minmax scaler since it varies quite a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = df.drop(columns='CASE_STATUS')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['CASE_STATUS'])\n",
    "\n",
    "X[['PREVAILING_WAGE']] = scaler.fit_transform(X[['PREVAILING_WAGE']])\n",
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize and train a XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ml/ml_env/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7238074957410562\n",
      "[0 0 0 ... 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ml/ml_env/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(random_state=99, nthread=11)\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "# print(xgb.feature_importances_)\n",
    "print(xgb.score(X_test, y_test))\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "print(xgb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** XGB Classifier Stats (OVERALL testset)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.78      0.73      6626\n",
      "          1       0.78      0.67      0.72      7462\n",
      "\n",
      "avg / total       0.73      0.72      0.72     14088\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, fbeta_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "print(\"** XGB Classifier Stats (OVERALL testset)\")\n",
    "print(classification_report(y_test, xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'H1B_DEPENDENT_N', 0.22089207)\n",
      "('WAGE_LOWER_THAN_PW', 0.18790165)\n",
      "(u'VISA_CLASS_H-1B', 0.121546865)\n",
      "(u'PW_SOURCE_Other', 0.057632793)\n",
      "('NAICS_CODE_541511', 0.04291458)\n",
      "(u'PW_SOURCE_OES', 0.03331062)\n",
      "(u'PREVAILING_WAGE', 0.028017666)\n",
      "('NAICS_CODE_611310', 0.02222083)\n",
      "('SOC_CODE_15-1132', 0.015854584)\n",
      "('NAICS_CODE_CAPGEMINIAMERICAINC', 0.013849134)\n",
      "('NAICS_CODE_54151', 0.011991634)\n",
      "('NAICS_CODE_51121', 0.0117135625)\n",
      "('SOC_CODE_15-1121', 0.011516797)\n",
      "('NAICS_CODE_334413', 0.009613371)\n",
      "('NAICS_CODE_518112', 0.009264715)\n",
      "('SOC_CODE_15-2041', 0.008028058)\n",
      "('SOC_CODE_29-1069', 0.0077255527)\n",
      "('SOC_CODE_29-2011', 0.007722302)\n",
      "('SOC_CODE_19-1029', 0.007434772)\n",
      "('NAICS_CODE_541512', 0.0074032987)\n",
      "('SOC_CODE_19-1042', 0.007357748)\n",
      "('SOC_CODE_23-1011', 0.007092336)\n",
      "(u'WAGE_UNIT_OF_PAY_Month', 0.0070633255)\n",
      "(u'PW_SOURCE_CBA', 0.006945116)\n",
      "('NAICS_CODE_ACCENTURELLP', 0.0065460377)\n",
      "('NAICS_CODE_54161', 0.006511824)\n",
      "('SOC_CODE_15-1199', 0.006456011)\n",
      "(u'PW_SOURCE_SCA', 0.0060395407)\n",
      "('SOC_CODE_11-1021', 0.0056629293)\n",
      "(u'WAGE_UNIT_OF_PAY_Hour', 0.005646819)\n",
      "(u'FULL_TIME_POSITION_N', 0.0055475235)\n",
      "('SOC_CODE_29-1131', 0.0054979073)\n",
      "('NAICS_CODE_454111', 0.005300169)\n",
      "('NAICS_CODE_561310', 0.005176964)\n",
      "('NAICS_CODE_551112', 0.0051718755)\n",
      "('NAICS_CODE_336111', 0.0051649814)\n",
      "('SOC_CODE_19-4021', 0.005134498)\n",
      "('NAICS_CODE_541211', 0.0050661457)\n",
      "('SOC_CODE_11-1011', 0.004938237)\n",
      "('NAICS_CODE_523110', 0.0048690517)\n",
      "('NAICS_CODE_32541', 0.004820664)\n",
      "('SOC_CODE_15-2031', 0.0046197413)\n",
      "('NAICS_CODE_54133', 0.004613871)\n",
      "('NAICS_CODE_446110', 0.0041176486)\n",
      "('SOC_CODE_15-1131', 0.0038400758)\n",
      "('NAICS_CODE_54111', 0.0037535974)\n",
      "('NAICS_CODE_523920', 0.003169787)\n",
      "('NAICS_CODE_541618', 0.0024110659)\n",
      "('NAICS_CODE_54194', 0.0022063046)\n",
      "('SOC_CODE_25-1022', 0.0019191611)\n",
      "('SOC_CODE_11-3021', 0.001916613)\n",
      "(u'WAGE_UNIT_OF_PAY_Year', 0.0018192651)\n",
      "('NAICS_CODE_541711', 0.001650452)\n",
      "('SOC_CODE_15-1133', 0.0008546046)\n",
      "('NAICS_CODE_541940', 0.00080484536)\n",
      "('SOC_CODE_13-1161', 0.00054084545)\n",
      "('SOC_CODE_13-2011', 0.00043088951)\n",
      "('SOC_CODE_17-2051', 0.0003929106)\n",
      "('NAICS_CODE_541922', 0.00023948007)\n",
      "('SOC_CODE_45-2011', 0.00022818665)\n",
      "('NAICS_CODE_541690', 0.000223301)\n",
      "('NAICS_CODE_31213', 0.00020353719)\n",
      "('SOC_CODE_11-9111', 0.00020173601)\n",
      "(u'WAGE_UNIT_OF_PAY_Week', 0.00019555479)\n",
      "('SOC_CODE_27-1025', 0.00016136024)\n",
      "('SOC_CODE_27-2012', 0.00015580596)\n",
      "('NAICS_CODE_424210', 0.00014998713)\n",
      "('SOC_CODE_13-1071', 0.00014318827)\n",
      "('NAICS_CODE_611620', 0.00013962689)\n",
      "('SOC_CODE_29-1051', 0.00010972478)\n",
      "('NAICS_CODE_621112', 9.4185045e-05)\n",
      "('SOC_CODE_17-2141', 8.249002e-05)\n",
      "('NAICS_CODE_445110', 4.560332e-05)\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "nonzero_features = {}\n",
    "for i in range(len(xgb.feature_importances_)):\n",
    "    if xgb.feature_importances_[i] > 0.0:\n",
    "        nonzero_features[list(X_train.columns)[i]] = xgb.feature_importances_[i]\n",
    "sorted_result = sorted(nonzero_features.items(), key=operator.itemgetter(1)) \n",
    "for i in range(len(sorted_result)):\n",
    "    print(sorted_result[-(i+1)])\n",
    "\n",
    "# with open('/tmp/feature_importances_first_800k_xgb.pickle', 'wb') as f:\n",
    "#     pickle.dump(sorted_result, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with open('/tmp/feature_importances_first_800k_xgb_dict.pickle', 'wb') as f:\n",
    "#     pickle.dump(nonzero_features, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** XGB Classifier Scores (OVERALL testset)\n",
      "Precision: 0.7779853650941927\n",
      "Recall: 0.6696596086839989\n",
      "Accuracy score: 0.7238074957410562\n",
      "F-1 score: 0.7197695354699315\n",
      "F-beta score with beta=0.5: 0.753604391626953\n",
      "F-beta score with beta=0.2: 0.7731749555157494\n",
      "Confusion Matrix: \n",
      "[[5200 1426]\n",
      " [2465 4997]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"** XGB Classifier Scores (OVERALL testset)\")\n",
    "print(\"Precision: %s\" % precision_score(y_test, xgb_pred))\n",
    "print(\"Recall: %s\"% recall_score(y_test, xgb_pred))\n",
    "print(\"Accuracy score: %s\"% accuracy_score(y_test, xgb_pred))\n",
    "print(\"F-1 score: %s\"% f1_score(y_test, xgb_pred))\n",
    "print(\"F-beta score with beta=0.5: %s\"% fbeta_score(y_test, xgb_pred, beta=0.5))\n",
    "print(\"F-beta score with beta=0.2: %s\"% fbeta_score(y_test, xgb_pred, beta=0.2))\n",
    "print(\"Confusion Matrix: \\n%s\"% confusion_matrix(y_test, xgb_pred))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ml/ml_env/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ones_index = y_test.nonzero()\n",
    "x_ones = X_test.iloc[ones_index]\n",
    "y_ones = np.take(y_test, ones_index)[0]\n",
    "\n",
    "xgb_pred_oneonly = xgb.predict(x_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** XGB Classifier Scores (Only rows with label DENIED->1)\n",
      "Precision: 1.0\n",
      "Recall: 0.6696596086839989\n",
      "Accuracy score: 0.6696596086839989\n",
      "F-1 score: 0.802151055461915\n",
      "F-beta score with beta=0.5: 0.910200364298725\n",
      "F-beta score with beta=0.2: 0.9813803470129243\n",
      "Confusion Matrix: \n",
      "[[   0    0]\n",
      " [2465 4997]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"** XGB Classifier Scores (Only rows with label DENIED->1)\")\n",
    "print(\"Precision: %s\" % precision_score(y_ones, xgb_pred_oneonly))\n",
    "print(\"Recall: %s\"% recall_score(y_ones, xgb_pred_oneonly))\n",
    "print(\"Accuracy score: %s\"% accuracy_score(y_ones, xgb_pred_oneonly))\n",
    "print(\"F-1 score: %s\"% f1_score(y_ones, xgb_pred_oneonly))\n",
    "print(\"F-beta score with beta=0.5: %s\"% fbeta_score(y_ones, xgb_pred_oneonly, beta=0.5))\n",
    "print(\"F-beta score with beta=0.2: %s\"% fbeta_score(y_ones, xgb_pred_oneonly, beta=0.2))\n",
    "print(\"Confusion Matrix: \\n%s\"% confusion_matrix(y_ones, xgb_pred_oneonly))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ml/ml_env/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "zeros_index = np.arange(len(y_test))[(y_test==0)]\n",
    "\n",
    "x_zeros = X_test.iloc[zeros_index]\n",
    "y_zeros = np.take(y_test, zeros_index)\n",
    "\n",
    "xgb_pred_zeroonly = xgb.predict(x_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** XGB Classifier Scores (Only rows with label CERTIFIED->0)\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "Accuracy score: 0.7847872019317839\n",
      "F-1 score: 0.0\n",
      "F-beta score with beta=0.5: 0.0\n",
      "F-beta score with beta=0.2: 0.0\n",
      "Confusion Matrix: \n",
      "[[5200 1426]\n",
      " [   0    0]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ml/ml_env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/ml/ml_env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"** XGB Classifier Scores (Only rows with label CERTIFIED->0)\")\n",
    "print(\"Precision: %s\" % precision_score(y_zeros, xgb_pred_zeroonly))\n",
    "print(\"Recall: %s\"% recall_score(y_zeros, xgb_pred_zeroonly))\n",
    "print(\"Accuracy score: %s\"% accuracy_score(y_zeros, xgb_pred_zeroonly))\n",
    "print(\"F-1 score: %s\"% f1_score(y_zeros, xgb_pred_zeroonly))\n",
    "print(\"F-beta score with beta=0.5: %s\"% fbeta_score(y_zeros, xgb_pred_zeroonly, beta=0.5))\n",
    "print(\"F-beta score with beta=0.2: %s\"% fbeta_score(y_zeros, xgb_pred_zeroonly, beta=0.2))\n",
    "print(\"Confusion Matrix: \\n%s\"% confusion_matrix(y_zeros, xgb_pred_zeroonly))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
