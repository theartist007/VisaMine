{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load cleaned up version of dataset from 2012 to 2018.  Drop geographic information about employer and worksite to reduce dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('/Users/minse_chang/PycharmProjects/Udacity_ML_Capstone/data/H1B_15-18_new.pickle')\n",
    "df.drop(columns=['EMPLOYER_CITY','JOB_TITLE','EMPLOYER_NAME'], inplace=True)\n",
    "df.drop(columns=['EMPLOYER_STATE','WORKSITE_STATE'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_df = df[df['CASE_STATUS']=='DENIED']\n",
    "zeros_df = df[df['CASE_STATUS']=='CERTIFIED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat([ones_df, zeros_df.sample(frac=0.1, random_state=99)])\n",
    "df = pd.concat([ones_df, zeros_df.sample(frac=0.02, random_state=99)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37310, 11)\n"
     ]
    }
   ],
   "source": [
    "ones_df.head()\n",
    "print(ones_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1656369, 11)\n"
     ]
    }
   ],
   "source": [
    "zeros_df.head()\n",
    "print(zeros_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use column 'CASE_STATUS' as our label.  DENIED will be 1 and CERTIFIED will be 0 after it gets incoded by label_encoder.\n",
    "\n",
    "Normalize PREVAILING_WAGE using minmax scaler since it varies quite a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = df.drop(columns='CASE_STATUS')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['CASE_STATUS'])\n",
    "\n",
    "X[['PREVAILING_WAGE']] = scaler.fit_transform(X[['PREVAILING_WAGE']])\n",
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 400\n",
    "pca = PCA(n_components=n_components, whiten=True, svd_solver='randomized')\n",
    "pca = pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 20.352s\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t0 = time()\n",
    "# eigenfaces = pca.components_.reshape((n_components, h, w))\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check value counts to verify stratify split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_train.value_counts())\n",
    "# print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train DecisionTreeClassifier and predict using X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(gamma=0.001, C=100)\n",
    "\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "svc_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train RandomForestClassifier and predict using X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** SV Classifier Stats (OVERALL testset)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.80      0.74      6652\n",
      "          1       0.79      0.68      0.73      7436\n",
      "\n",
      "avg / total       0.74      0.74      0.74     14088\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(\"** SV Classifier Stats (OVERALL testset)\")\n",
    "print(classification_report(y_test, svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svc_final.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(svc, 'svc_final.pkl', compress=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the trained model to a pickle file in case we need it in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc = joblib.load('svc.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the pre-trained model, run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** SV Classifier Scores (OVERALL testset)\n",
      "Precision: 0.7943777637397347\n",
      "Recall: 0.6764389456697149\n",
      "Accuracy score: 0.7367972742759795\n",
      "F-1 score: 0.730679837303893\n",
      "F-beta score with beta=0.5: 0.7676107923330485\n",
      "F-beta score with beta=0.2: 0.7890862576627891\n",
      "Confusion Matrix: \n",
      "[[5350 1302]\n",
      " [2406 5030]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, fbeta_score, accuracy_score, confusion_matrix\n",
    "\n",
    "print(\"** SV Classifier Scores (OVERALL testset)\")\n",
    "print(\"Precision: %s\"% precision_score(y_test, svc_pred))\n",
    "print(\"Recall: %s\"% recall_score(y_test, svc_pred))\n",
    "print(\"Accuracy score: %s\"% accuracy_score(y_test, svc_pred))\n",
    "print(\"F-1 score: %s\"% f1_score(y_test, svc_pred))\n",
    "print(\"F-beta score with beta=0.5: %s\"% fbeta_score(y_test, svc_pred, beta=0.5))\n",
    "print(\"F-beta score with beta=0.2: %s\"% fbeta_score(y_test, svc_pred, beta=0.2))\n",
    "print(\"Confusion Matrix: \\n%s\"% confusion_matrix(y_test, svc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate stats for the entire test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(data=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ones_index = y_test.nonzero()[0]\n",
    "x_ones = X_test[ones_index,:]\n",
    "y_ones = np.take(y_test, ones_index)\n",
    "\n",
    "# print(x_ones.shape)\n",
    "# print(y_ones.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pred_oneonly = svc.predict(x_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** SV Classifier Scores (Only rows with label DENIED->1)\n",
      "Precision: 1.0\n",
      "Recall: 0.6764389456697149\n",
      "Accuracy score: 0.6764389456697149\n",
      "F-1 score: 0.8069950264720038\n",
      "F-beta score with beta=0.5: 0.9126868921469009\n",
      "F-beta score with beta=0.2: 0.98193503821723\n",
      "Confusion Matrix: \n",
      "[[   0    0]\n",
      " [2406 5030]]\n"
     ]
    }
   ],
   "source": [
    "print(\"** SV Classifier Scores (Only rows with label DENIED->1)\")\n",
    "print(\"Precision: %s\"% precision_score(y_ones, svc_pred_oneonly))\n",
    "print(\"Recall: %s\"% recall_score(y_ones, svc_pred_oneonly))\n",
    "print(\"Accuracy score: %s\"% accuracy_score(y_ones, svc_pred_oneonly))\n",
    "print(\"F-1 score: %s\"% f1_score(y_ones, svc_pred_oneonly))\n",
    "print(\"F-beta score with beta=0.5: %s\"% fbeta_score(y_ones, svc_pred_oneonly, beta=0.5))\n",
    "print(\"F-beta score with beta=0.2: %s\"% fbeta_score(y_ones, svc_pred_oneonly, beta=0.2))\n",
    "print(\"Confusion Matrix: \\n%s\"% confusion_matrix(y_ones, svc_pred_oneonly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate stats for testset with label 1 (DENIED cases only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_index = np.arange(len(y_test))[(y_test==0)]\n",
    "x_zeros = X_test[zeros_index,:]\n",
    "y_zeros = np.take(y_test, zeros_index)\n",
    "svc_pred_zeroonly = svc.predict(x_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** SV Classifier Scores (Only rows with label CERTIFIED->0)\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "Accuracy score: 0.8042693926638604\n",
      "F-1 score: 0.0\n",
      "F-beta score with beta=0.5: 0.0\n",
      "F-beta score with beta=0.2: 0.0\n",
      "Confusion Matrix: \n",
      "[[5350 1302]\n",
      " [   0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ml/ml_env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/ml/ml_env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"** SV Classifier Scores (Only rows with label CERTIFIED->0)\")\n",
    "print(\"Precision: %s\"% precision_score(y_zeros, svc_pred_zeroonly))\n",
    "print(\"Recall: %s\"% recall_score(y_zeros, svc_pred_zeroonly))\n",
    "print(\"Accuracy score: %s\"% accuracy_score(y_zeros, svc_pred_zeroonly))\n",
    "print(\"F-1 score: %s\"% f1_score(y_zeros, svc_pred_zeroonly))\n",
    "print(\"F-beta score with beta=0.5: %s\"% fbeta_score(y_zeros, svc_pred_zeroonly, beta=0.5))\n",
    "print(\"F-beta score with beta=0.2: %s\"% fbeta_score(y_zeros, svc_pred_zeroonly, beta=0.2))\n",
    "print(\"Confusion Matrix: \\n%s\"% confusion_matrix(y_zeros, svc_pred_zeroonly))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2018, 12, 19, 11, 36, 58, 534773)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VISA_CLASS       CASE_STATUS\n",
       "E-3 Australian   CERTIFIED        878\n",
       "                 DENIED          3889\n",
       "H-1B             CERTIFIED      47457\n",
       "                 DENIED         32924\n",
       "H-1B1 Chile      CERTIFIED         75\n",
       "                 DENIED           291\n",
       "H-1B1 Singapore  CERTIFIED         89\n",
       "                 DENIED           206\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['VISA_CLASS','CASE_STATUS']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
