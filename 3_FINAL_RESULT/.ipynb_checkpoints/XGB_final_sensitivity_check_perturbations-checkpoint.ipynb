{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load cleaned up version of dataset from 2012 to 2018.  Drop geographic information about employer and worksite to reduce dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('/Users/ml/Desktop/Udacity_ML_Capstone/data/H1B_15-18_new.pickle')\n",
    "df.drop(columns=['EMPLOYER_CITY','JOB_TITLE','EMPLOYER_NAME'], inplace=True)\n",
    "df.drop(columns=['EMPLOYER_STATE','WORKSITE_STATE'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_df = df[df['CASE_STATUS']=='DENIED']\n",
    "zeros_df = df[df['CASE_STATUS']=='CERTIFIED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_zeros_df = zeros_df.sample(frac=0.02, random_state=99)\n",
    "df = pd.concat([ones_df, sampled_zeros_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['CASE_STATUS'])\n",
    "y = df['CASE_STATUS'].apply(lambda x: 1 if x=='DENIED' else 0).values\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X[['PREVAILING_WAGE']] = scaler.fit_transform(X[['PREVAILING_WAGE']])\n",
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slighyly manipulate a few features of X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiply prevailing wage by a random number between 0.95 and 1.05.\n",
    "\n",
    "At 2% probability, flip the boolean categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ml/ml_env/lib/python2.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "random_constants = np.random.uniform(0.95,1.05,X_test.shape[0])\n",
    "X_test['PREVAILING_WAGE'] = X_test['PREVAILING_WAGE'] * random_constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ml/ml_env/lib/python2.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/ml/ml_env/lib/python2.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/ml/ml_env/lib/python2.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/ml/ml_env/lib/python2.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/ml/ml_env/lib/python2.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/Users/ml/ml_env/lib/python2.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/ml/ml_env/lib/python2.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "choices = [True, False]\n",
    "prob = [0.02, 0.98]\n",
    "# Toss a coin\n",
    "# flipped_indices = np.nonzero(np.random.choice(choices, X_test.shape[0], p=prob))\n",
    "X_test['WAGE_LOWER_THAN_PW'] = X_test['WAGE_LOWER_THAN_PW'].apply(\n",
    "    lambda x: not x if np.random.choice(choices, 1, p=prob)[0] else x)\n",
    "X_test['FULL_TIME_POSITION_N'] = X_test['FULL_TIME_POSITION_N'].apply(\n",
    "    lambda x: 1-x if np.random.choice(choices, 1, p=prob)[0] else x)\n",
    "X_test['FULL_TIME_POSITION_Y'] = X_test['FULL_TIME_POSITION_N'].apply(\n",
    "    lambda x: 1-x if np.random.choice(choices, 1, p=prob)[0] else x)\n",
    "X_test['H1B_DEPENDENT_N'] = X_test['H1B_DEPENDENT_N'].apply(\n",
    "    lambda x: 1-x if np.random.choice(choices, 1, p=prob)[0] else x)\n",
    "X_test['H1B_DEPENDENT_Y'] = X_test['H1B_DEPENDENT_Y'].apply(\n",
    "    lambda x: 1-x if np.random.choice(choices, 1, p=prob)[0] else x)\n",
    "X_test['WILLFUL_VIOLATOR_N'] = X_test['WILLFUL_VIOLATOR_N'].apply(\n",
    "    lambda x: 1-x if np.random.choice(choices, 1, p=prob)[0] else x)\n",
    "X_test['WILLFUL_VIOLATOR_Y'] = X_test['WILLFUL_VIOLATOR_Y'].apply(\n",
    "    lambda x: 1-x if np.random.choice(choices, 1, p=prob)[0] else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train XGBoost classifier and predict using X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=11, objective='binary:logistic', random_state=99,\n",
       "       reg_alpha=0.06, reg_lambda=0.07, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(random_state=99,reg_alpha=0.06, \n",
    "colsample_bytree=0.8, \n",
    "n_estimators=1000, \n",
    "subsample=0.9, \n",
    "reg_lambda=0.07, \n",
    "max_depth=3, \n",
    "gamma=2, nthread=11)\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "# print(xgb.feature_importances_)\n",
    "# print(xgb.score(X_test, y_test))\n",
    "# xgb_pred = xgb.predict(X_test)\n",
    "# print(xgb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ml/ml_env/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "xgb_pred = xgb.predict(X_test)\n",
    "# X_test_sensitivity.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate prediction result with the manipulated X_test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** XGBoost Classifier Stats (OVERALL testset)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.42      0.54      6629\n",
      "          1       0.63      0.89      0.74      7459\n",
      "\n",
      "avg / total       0.70      0.67      0.65     14088\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(\"** XGBoost Classifier Stats (OVERALL testset)\")\n",
    "print(classification_report(y_test, xgb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the trained model to a pickle file in case we need it in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate stats for the entire test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** XGBoost Classifier Scores (OVERALL testset)\n",
      "Precision: 0.6336793980379084\n",
      "Recall: 0.8919426196541091\n",
      "Accuracy score: 0.6697898921067575\n",
      "F-1 score: 0.7409511081412185\n",
      "F-beta score with beta=0.5: 0.6726316853705389\n",
      "F-beta score with beta=0.2: 0.6408159031466951\n",
      "Confusion Matrix: \n",
      "[[2783 3846]\n",
      " [ 806 6653]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, fbeta_score, accuracy_score, confusion_matrix\n",
    "\n",
    "print(\"** XGBoost Classifier Scores (OVERALL testset)\")\n",
    "print(\"Precision: %s\"% precision_score(y_test, xgb_pred))\n",
    "print(\"Recall: %s\"% recall_score(y_test, xgb_pred))\n",
    "print(\"Accuracy score: %s\"% accuracy_score(y_test, xgb_pred))\n",
    "print(\"F-1 score: %s\"% f1_score(y_test, xgb_pred))\n",
    "print(\"F-beta score with beta=0.5: %s\"% fbeta_score(y_test, xgb_pred, beta=0.5))\n",
    "print(\"F-beta score with beta=0.2: %s\"% fbeta_score(y_test, xgb_pred, beta=0.2))\n",
    "print(\"Confusion Matrix: \\n%s\"% confusion_matrix(y_test, xgb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate stats for testset with label 1 (DENIED cases only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ml/ml_env/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ones_index = y_test.nonzero()\n",
    "x_ones = X_test.iloc[ones_index]\n",
    "y_ones = np.take(y_test, ones_index)[0]\n",
    "\n",
    "xgb_pred_oneonly = xgb.predict(x_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** XGBoost Classifier Scores (Only rows with label DENIED->1)\n",
      "Precision: 1.0\n",
      "Recall: 0.8919426196541091\n",
      "Accuracy score: 0.8919426196541091\n",
      "F-1 score: 0.9428854875283447\n",
      "F-beta score with beta=0.5: 0.9763435179478149\n",
      "F-beta score with beta=0.2: 0.9953620586475165\n",
      "Confusion Matrix: \n",
      "[[   0    0]\n",
      " [ 806 6653]]\n"
     ]
    }
   ],
   "source": [
    "print(\"** XGBoost Classifier Scores (Only rows with label DENIED->1)\")\n",
    "print(\"Precision: %s\"% precision_score(y_ones, xgb_pred_oneonly))\n",
    "print(\"Recall: %s\"% recall_score(y_ones, xgb_pred_oneonly))\n",
    "print(\"Accuracy score: %s\"% accuracy_score(y_ones, xgb_pred_oneonly))\n",
    "print(\"F-1 score: %s\"% f1_score(y_ones, xgb_pred_oneonly))\n",
    "print(\"F-beta score with beta=0.5: %s\"% fbeta_score(y_ones, xgb_pred_oneonly, beta=0.5))\n",
    "print(\"F-beta score with beta=0.2: %s\"% fbeta_score(y_ones, xgb_pred_oneonly, beta=0.2))\n",
    "print(\"Confusion Matrix: \\n%s\"% confusion_matrix(y_ones, xgb_pred_oneonly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate stats for testset with label 0 (CERTIFIED cases only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ml/ml_env/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "zeros_index = np.arange(len(y_test))[(y_test==0)]\n",
    "\n",
    "x_zeros = X_test.iloc[zeros_index]\n",
    "y_zeros = np.take(y_test, zeros_index)\n",
    "xgb_pred_zeroonly = xgb.predict(x_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** XGBoost Classifier Scores (Only rows with label CERTIFIED->0)\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "Accuracy score: 0.419821994267612\n",
      "F-1 score: 0.0\n",
      "F-beta score with beta=0.5: 0.0\n",
      "F-beta score with beta=0.2: 0.0\n",
      "Confusion Matrix: \n",
      "[[2783 3846]\n",
      " [   0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ml/ml_env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/ml/ml_env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"** XGBoost Classifier Scores (Only rows with label CERTIFIED->0)\")\n",
    "print(\"Precision: %s\"% precision_score(y_zeros, xgb_pred_zeroonly))\n",
    "print(\"Recall: %s\"% recall_score(y_zeros, xgb_pred_zeroonly))\n",
    "print(\"Accuracy score: %s\"% accuracy_score(y_zeros, xgb_pred_zeroonly))\n",
    "print(\"F-1 score: %s\"% f1_score(y_zeros, xgb_pred_zeroonly))\n",
    "print(\"F-beta score with beta=0.5: %s\"% fbeta_score(y_zeros, xgb_pred_zeroonly, beta=0.5))\n",
    "print(\"F-beta score with beta=0.2: %s\"% fbeta_score(y_zeros, xgb_pred_zeroonly, beta=0.2))\n",
    "print(\"Confusion Matrix: \\n%s\"% confusion_matrix(y_zeros, xgb_pred_zeroonly))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2018, 12, 21, 1, 54, 4, 490268)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "datetime.datetime.now()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
